{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeL7QZ07BvVuTpwsuahmdX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zulfiqaralimir/LangChain-UseCases/blob/master/chatgpt_for_your_own_pdf_files_with_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ChatGPT for YOUR OWN PDF files with LangChain.**"
      ],
      "metadata": {
        "id": "GXdDKAJBd0DF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Required Packages**"
      ],
      "metadata": {
        "id": "9-_-UyKn-Bnr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlorSbccWEDa"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install PyPDF2\n",
        "!pip install faiss-cpu\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading the Packages**"
      ],
      "metadata": {
        "id": "67sDX2vA_VFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS"
      ],
      "metadata": {
        "id": "nq0vKGFeW1KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Operating System and API Key**"
      ],
      "metadata": {
        "id": "TELIzdYzAEgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your API keys from openai, you will need to create an account.\n",
        "# Here is the link to get the keys: https://platform.openai.com/account/billing/overview\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR-OPENAI-API-KEY\""
      ],
      "metadata": {
        "id": "vnz-Pql1AE7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Connecting to Google Drive for PDF File**"
      ],
      "metadata": {
        "id": "FjpBofIbC7ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\""
      ],
      "metadata": {
        "id": "bh3Y5bDlC8OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading the PDF File from Google Drive**"
      ],
      "metadata": {
        "id": "vNlnKdZyD8vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# location of the pdf file/files.\n",
        "reader = PdfReader('/content/gdrive/My Drive/Colab Notebooks/2023_GPT4All_Technical_Report.pdf')"
      ],
      "metadata": {
        "id": "5JUwrdvyD8_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reader Object (It has all info how to read PDF File)**"
      ],
      "metadata": {
        "id": "tf2ec7wbGaYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reader"
      ],
      "metadata": {
        "id": "hVFKbxF8GIwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Raw Text**"
      ],
      "metadata": {
        "id": "2L9iBa8tG2t8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read data from the file and put them into a variable called raw_text\n",
        "raw_text = ''\n",
        "for i, page in enumerate(reader.pages):\n",
        "    text = page.extract_text()\n",
        "    if text:\n",
        "        raw_text += text"
      ],
      "metadata": {
        "id": "bSUj4px5G271"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "id": "xgH1psxaHdre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **?**"
      ],
      "metadata": {
        "id": "03AdvvKRIh2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mXjc1UxRIcKQ",
        "outputId": "2c9f43bd-d8f3-4093-d5df-9c7f4bf38619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GPT4All: Training an Assistant-style Chatbot with Large Scale Data\\nDistillation from GPT-3.5-Turbo\\nY'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Splitting into Chunks to avoid Token Size Limits**"
      ],
      "metadata": {
        "id": "G9RSGyMMI3T4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to split the text that we read into smaller chunks so that during information retreival we don't hit the token size limits.\n",
        "\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "mVUK453AI3xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **No of Chunks**"
      ],
      "metadata": {
        "id": "RpAT65PXJltE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "id": "3-hj3BOoJmCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading the First Chunk**"
      ],
      "metadata": {
        "id": "MR-8-4CSJ5pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0]"
      ],
      "metadata": {
        "id": "9wD8e9LPJ-F4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Second Chunk** (Check the overlap between Two Chuncks) (Optional but Helping)"
      ],
      "metadata": {
        "id": "oDcdcgqkKW6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts[1]"
      ],
      "metadata": {
        "id": "Zvnd1N8IKbZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Downloading the Embedding from OpenAI** (Need API Key)\n",
        "Embedding is List of Float Numbers (It measure the distance b/w Two Text Strings / Sentences."
      ],
      "metadata": {
        "id": "_kxe6tyUKgGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download embeddings from OpenAI\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "DWaFpfPML2OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vector Database (**Taking the Chunks and finding corresponing Embeddings)\n",
        "It will be stored in 'docsearch'"
      ],
      "metadata": {
        "id": "RSpRhwBwNxCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = FAISS.from_texts(texts, embeddings)"
      ],
      "metadata": {
        "id": "n9NGbLNwNI9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch"
      ],
      "metadata": {
        "id": "VHzo7l5ENKhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing **QnA Chain** from LangChain and Corresponding OpenAI Object"
      ],
      "metadata": {
        "id": "tQw8SRUZQlT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "BC3VZGq-QjxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Passing different Models** (It will create a Chain)\n",
        "(text ada-001)\n",
        "Capbable of very Simple Tasks, usually the Fastest model in GPT-3 series, and lowest in cost.\n",
        "2049 tokens\n",
        "up to OCT 2019"
      ],
      "metadata": {
        "id": "y8kRVlUoSwav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "9-tD5mmlSuLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Start Asking Questions**\n",
        "(From embedding, it find using semantically search, closest text in document)"
      ],
      "metadata": {
        "id": "bGjHLkCtX3fB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"who are the authors of the article?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "0gp776mYX3qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Next Query**"
      ],
      "metadata": {
        "id": "Jcu5LX2IaPM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What was the cost of training the GPT4all model?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "oUHsms2xaSd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Some other Questions**"
      ],
      "metadata": {
        "id": "wcuZgs_Dammb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How was the model trained?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "htJLJdyhaqr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what was the size of the training dataset?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "3tkuTZcZawHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#it is not exact answer because this information is not present in the paper.\n",
        "query = \"How is this different from other models?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "bMD22QZba4qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer: I don't know. (It is not in the Technical Report)\n",
        "query = \"What is Google Bard?\"\n",
        "docs = docsearch.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "id": "Z-VwEk2Ha8Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vidoe Line:**\n",
        "\n",
        "https://www.youtube.com/watch?v=TLf90ipMzfE\n",
        "\n",
        "https://www.toolspedia.io/ai-tool/pdfgpt/\n",
        "\n",
        "https://www.pdfgpt.io/plan\n"
      ],
      "metadata": {
        "id": "NCON_z-lbqPg"
      }
    }
  ]
}